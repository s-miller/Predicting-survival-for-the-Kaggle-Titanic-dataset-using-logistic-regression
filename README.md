# Predicting survival for the Kaggle Titanic dataset using logistic regression

The Titanic dataset appears to have become the "Hello World" of machine learning.  

I was feeling left out, not having a mention of it on my Github.

So here goes: A very quick and dirty approach with some prep of the dataset, but minimal tweaking of the model, to see what sort of performance can be had with an *out of the box* logistic regression classifier.

(spoiler alert)

...not bad: f-score 81%.

URL: https://www.kaggle.com/c/titanic/data

As an aside, some useful learning had here about good and bad ways to (try to) write values to a dataframe!
